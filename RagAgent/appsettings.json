{
   "Serilog": {
      "Using": [],
      "MinimumLevel": {
         "Default": "Information",
         "Override": {
            "Microsoft": "Warning",
            "System": "Warning",
            "Polly": "Warning",
            //"ChatPrompt": "Verbose",                                                // Log the input parameters for the prompt generation
            //"Microsoft.Extensions.AI.LoggingEmbeddingGenerator": "Verbose",         // Log the embeddings requests and resposes
            "Microsoft.SemanticKernel.KernelFunction": "Verbose",                   // Log the kernel function calls
            "Microsoft.SemanticKernel.KernelFunctionFactory": "Verbose",             // Log the prompt redering
            //"Microsoft.Extensions.AI.LoggingChatClient": "Verbose"                  // Log the chat requests and responses
            "SemanticChunker.TextChunker" : "Verbose"
         }
      },
      "Enrich": [ "FromLogContext", "WithMachineName", "WithProcessId", "WithThreadId" ],
      "WriteTo": [
         {
            "Name": "Console",
            "Args": {
               "theme": "Serilog.Sinks.SystemConsole.Themes.AnsiConsoleTheme::Code, Serilog.Sinks.Console",
               "outputTemplate": "[{Timestamp:yyyy-MM-dd HH:mm:ss} {Level:u3}]  {SourceContext}  {Message:lj}{NewLine}{Exception}"
            }
         }
      ]
   },

   "EmbeddingService": {
      "ModelId": "nomic-embed-text",
      "Endpoint": "http://localhost:11434"
   },

   "ChatService": {
      "ModelId": "llama3.2",
      "Endpoint": "http://localhost:11434"
   },

   "Dataloader": {
      "DegreeOfParallelism": 1,
      "MaxTokensPerChunk": 400,
      "Documents": [
         "sn-1025.txt"
      ]
   }
}